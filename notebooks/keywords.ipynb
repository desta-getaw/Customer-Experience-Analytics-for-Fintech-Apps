{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6050af59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Keywords:\n",
      "\n",
      "good — 328.04\n",
      "app — 235.80\n",
      "best — 149.68\n",
      "nice — 112.73\n",
      "bank — 76.66\n",
      "ok — 60.08\n",
      "best app — 58.80\n",
      "wow — 57.45\n",
      "banking — 54.11\n",
      "use — 52.17\n",
      "like — 50.50\n",
      "application — 49.79\n",
      "good app — 49.68\n",
      "great — 48.81\n",
      "excellent — 47.71\n",
      "work — 46.57\n",
      "fast — 46.08\n",
      "dashen — 46.00\n",
      "easy — 45.13\n",
      "amazing — 43.57\n",
      "super — 38.39\n",
      "mobile — 37.94\n",
      "working — 37.88\n",
      "cbe — 36.19\n",
      "ነው — 34.46\n",
      "boa — 33.33\n",
      "mobile banking — 29.21\n",
      "dashen bank — 27.08\n",
      "worst — 26.68\n",
      "easy use — 26.48\n",
      "\n",
      "Clustered Keywords:\n",
      "Other (30): ['good', 'app', 'best', 'nice', 'bank', 'ok', 'best app', 'wow', 'banking', 'use', 'like', 'application', 'good app', 'great', 'excellent', 'work', 'fast', 'dashen', 'easy', 'amazing', 'super', 'mobile', 'working', 'cbe', 'ነው', 'boa', 'mobile banking', 'dashen bank', 'worst', 'easy use']\n"
     ]
    }
   ],
   "source": [
    "# notebooks/keywords.ipynb\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "# Add the scripts directory to the Python path\n",
    "scripts_path = os.path.abspath('../scripts')\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "try:\n",
    "    #from scripts.keywords import KeywordExtractor\n",
    "    from keywords import KeywordExtractor\n",
    "\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    # If the import fails, provide a helpful error message\n",
    "    raise ModuleNotFoundError(\n",
    "        \"Could not find 'keywords.py' in '../scripts'. \"\n",
    "        \"Please ensure the file exists and the path is correct.\"\n",
    "    )\n",
    "# Ensure 'scripts' directory is in the path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), 'scripts')))\n",
    "\n",
    "\n",
    "\n",
    "# Load cleaned review data\n",
    "df = pd.read_csv(\"../data/cleaned_reviews.csv\")\n",
    "\n",
    "# Combine all review text into one Series\n",
    "reviews = df['review'].dropna().astype(str)\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = KeywordExtractor(method='tfidf', top_n=30)\n",
    "\n",
    "# Step 1: Extract Keywords\n",
    "top_keywords = extractor.extract_keywords(reviews)\n",
    "print(\"Top Keywords:\\n\")\n",
    "for kw, score in top_keywords:\n",
    "    print(f\"{kw} — {score:.2f}\")\n",
    "\n",
    "# Step 2: Cluster Keywords\n",
    "clusters = extractor.manual_cluster(top_keywords)\n",
    "\n",
    "# Display clusters\n",
    "print(\"\\nClustered Keywords:\")\n",
    "for category, kws in clusters.items():\n",
    "    print(f\"{category} ({len(kws)}): {kws}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c56b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Keyword clusters saved to outputs/keyword_clusters.csv\n",
      "✅ Keyword clusters saved to outputs/keyword_clusters.csv\n",
      "   Category         Keyword\n",
      "0     Other            good\n",
      "1     Other             app\n",
      "2     Other            best\n",
      "3     Other            nice\n",
      "4     Other            bank\n",
      "5     Other              ok\n",
      "6     Other        best app\n",
      "7     Other             wow\n",
      "8     Other         banking\n",
      "9     Other             use\n",
      "10    Other            like\n",
      "11    Other     application\n",
      "12    Other        good app\n",
      "13    Other           great\n",
      "14    Other       excellent\n",
      "15    Other            work\n",
      "16    Other            fast\n",
      "17    Other          dashen\n",
      "18    Other            easy\n",
      "19    Other         amazing\n",
      "20    Other           super\n",
      "21    Other          mobile\n",
      "22    Other         working\n",
      "23    Other             cbe\n",
      "24    Other              ነው\n",
      "25    Other             boa\n",
      "26    Other  mobile banking\n",
      "27    Other     dashen bank\n",
      "28    Other           worst\n",
      "29    Other        easy use\n"
     ]
    }
   ],
   "source": [
    "# Convert cluster dictionary to DataFrame\n",
    "cluster_data = []\n",
    "for category, kws in clusters.items():\n",
    "    for kw in kws:\n",
    "        cluster_data.append({\"Category\": category, \"Keyword\": kw})\n",
    "\n",
    "cluster_df = pd.DataFrame(cluster_data)\n",
    "##\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = \"../data/outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Then save the CSV\n",
    "cluster_df.to_csv(os.path.join(output_dir, \"keyword_clusters.csv\"), index=False)\n",
    "print(\"✅ Keyword clusters saved to outputs/keyword_clusters.csv\")\n",
    "\n",
    "# Export to CSV\n",
    "cluster_df.to_csv(\"../data/outputs/keyword_clusters.csv\", index=False)\n",
    "print(\"✅ Keyword clusters saved to outputs/keyword_clusters.csv\")\n",
    "df = pd.read_csv(\"../data/outputs/keyword_clusters.csv\")\n",
    "print(df.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428848bf",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Detailed Report: Keyword Extraction and Topic Modeling\n",
      "\n",
      "## 1. keywords.ipynb\n",
      "\n",
      "### Objective\n",
      "- Extract meaningful keywords from cleaned review data using TF-IDF.\n",
      "- Cluster the extracted keywords into categories for further analysis.\n",
      "\n",
      "### Steps Performed\n",
      "1. **Data Loading**: Loaded cleaned review data from '../data/cleaned_reviews.csv'.\n",
      "2. **Keyword Extraction**: \n",
      "    - Used the `KeywordExtractor` class (with TF-IDF method) to extract the top 30 keywords from the review texts.\n",
      "    - Displayed keywords along with their TF-IDF scores.\n",
      "3. **Keyword Clustering**:\n",
      "    - Clustered the extracted keywords into manually defined categories using the `manual_cluster` method.\n",
      "    - Displayed the clusters and their contents.\n",
      "4. **Exporting Results**:\n",
      "    - Converted the clusters into a DataFrame.\n",
      "    - Saved the clustered keywords to '../data/outputs/keyword_clusters.csv' for further use.\n",
      "\n",
      "### Outputs\n",
      "- Top keywords with scores.\n",
      "- Clustered keywords by category.\n",
      "- CSV file containing keyword clusters.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. topicm.ipynb\n",
      "\n",
      "### Objective\n",
      "- Perform topic modeling on the same or similar review dataset to identify main discussion topics.\n",
      "\n",
      "### Typical Steps (Assumed from Standard Topic Modeling Workflow)\n",
      "1. **Data Loading**: Load and preprocess review data.\n",
      "2. **Text Vectorization**: Convert text data into a suitable format (e.g., using CountVectorizer or TfidfVectorizer).\n",
      "3. **Topic Modeling**: \n",
      "    - Apply topic modeling algorithms such as Latent Dirichlet Allocation (LDA) or Non-negative Matrix Factorization (NMF).\n",
      "    - Extract top words for each topic.\n",
      "4. **Visualization & Interpretation**:\n",
      "    - Visualize topics and their representative keywords.\n",
      "    - Assign topic labels to reviews if needed.\n",
      "\n",
      "### Outputs\n",
      "- List of topics with representative keywords.\n",
      "- Visualizations (e.g., word clouds, bar charts).\n",
      "- CSV or DataFrame with topic assignments.\n",
      "\n",
      "---\n",
      "\n",
      "## Summary\n",
      "\n",
      "- **keywords.ipynb** focused on extracting and clustering important keywords from review data, providing insights into frequent terms and their groupings.\n",
      "- **topicm.ipynb** (assumed) performed topic modeling to uncover latent topics within the reviews, offering a higher-level thematic overview.\n",
      "- Both notebooks contribute to understanding the main themes and important terms in the review dataset, supporting further analysis or reporting.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare a detailed report summarizing the tasks performed in 'keywords.ipynb' and 'topicm.ipynb'\n",
    "\n",
    "report = \"\"\"\n",
    "# Detailed Report: Keyword Extraction and Topic Modeling\n",
    "\n",
    "## 1. keywords.ipynb\n",
    "\n",
    "### Objective\n",
    "- Extract meaningful keywords from cleaned review data using TF-IDF.\n",
    "- Cluster the extracted keywords into categories for further analysis.\n",
    "\n",
    "### Steps Performed\n",
    "1. **Data Loading**: Loaded cleaned review data from '../data/cleaned_reviews.csv'.\n",
    "2. **Keyword Extraction**: \n",
    "    - Used the `KeywordExtractor` class (with TF-IDF method) to extract the top 30 keywords from the review texts.\n",
    "    - Displayed keywords along with their TF-IDF scores.\n",
    "3. **Keyword Clustering**:\n",
    "    - Clustered the extracted keywords into manually defined categories using the `manual_cluster` method.\n",
    "    - Displayed the clusters and their contents.\n",
    "4. **Exporting Results**:\n",
    "    - Converted the clusters into a DataFrame.\n",
    "    - Saved the clustered keywords to '../data/outputs/keyword_clusters.csv' for further use.\n",
    "\n",
    "### Outputs\n",
    "- Top keywords with scores.\n",
    "- Clustered keywords by category.\n",
    "- CSV file containing keyword clusters.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. topicm.ipynb\n",
    "\n",
    "### Objective\n",
    "- Perform topic modeling on the same or similar review dataset to identify main discussion topics.\n",
    "\n",
    "### Typical Steps (Assumed from Standard Topic Modeling Workflow)\n",
    "1. **Data Loading**: Load and preprocess review data.\n",
    "2. **Text Vectorization**: Convert text data into a suitable format (e.g., using CountVectorizer or TfidfVectorizer).\n",
    "3. **Topic Modeling**: \n",
    "    - Apply topic modeling algorithms such as Latent Dirichlet Allocation (LDA) or Non-negative Matrix Factorization (NMF).\n",
    "    - Extract top words for each topic.\n",
    "4. **Visualization & Interpretation**:\n",
    "    - Visualize topics and their representative keywords.\n",
    "    - Assign topic labels to reviews if needed.\n",
    "\n",
    "### Outputs\n",
    "- List of topics with representative keywords.\n",
    "- Visualizations (e.g., word clouds, bar charts).\n",
    "- CSV or DataFrame with topic assignments.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **keywords.ipynb** focused on extracting and clustering important keywords from review data, providing insights into frequent terms and their groupings.\n",
    "- **topicm.ipynb** (assumed) performed topic modeling to uncover latent topics within the reviews, offering a higher-level thematic overview.\n",
    "- Both notebooks contribute to understanding the main themes and important terms in the review dataset, supporting further analysis or reporting.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
